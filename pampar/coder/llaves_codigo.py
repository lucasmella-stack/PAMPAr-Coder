# SPDX-License-Identifier: AGPL-3.0-or-later
# Copyright (c) 2024-2026 Lucas Ricardo Mella Chillemi
"""
LLAVES especializadas para c√≥digo.

Las LLAVES son el coraz√≥n del routing en PAMPAr.
Para c√≥digo, definimos patrones espec√≠ficos por lenguaje que activan
los territorios correctos instant√°neamente.

Sistema 70-80% reglas + 20-30% atenci√≥n aprendida.
"""

from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Dict, List, Set, Optional, Tuple
import re


def normalizar_token(token: str) -> str:
    """
    Normaliza token de SentencePiece/BPE para clasificaci√≥n.
    
    Los tokenizers agregan prefijos especiales:
    - SentencePiece: '‚ñÅ' (unicode 9601) para inicio de palabra
    - GPT-style: 'ƒ†' para espacios
    - Byte-level: 'ƒä' para newlines
    
    Sin esto, '‚ñÅdef' no matchea 'def' y todo va a SEM√ÅNTICA.
    """
    if not token:
        return token
    
    # Quitar prefijos de tokenizers
    token = token.replace('‚ñÅ', '')  # SentencePiece
    token = token.replace('ƒ†', '')  # GPT-2/GPT-Neo style
    token = token.replace('ƒä', '')  # Newline en byte-level
    token = token.replace('##', '') # BERT WordPiece
    
    # Limpiar espacios
    token = token.strip()
    
    return token


class TipoTerritorioCoder(Enum):
    """Territorios especializados para c√≥digo."""
    SINTAXIS = auto()      # Keywords, operadores, delimitadores
    SEMANTICA = auto()     # Nombres, strings, comentarios, contexto
    LOGICO = auto()        # Control flow, condiciones, loops
    ESTRUCTURAL = auto()   # Indentaci√≥n, bloques, scopes, patterns


@dataclass
class LlavesCodigo:
    """
    LLAVES (Linguistic Lexical Anchoring for Vectorized Entry Selection)
    especializado para tokens de c√≥digo.
    
    Cada token puede activar 1 o m√°s territorios con diferentes pesos.
    """
    
    # =========================================================================
    # TERRITORIO SINTAXIS - Keywords y operadores
    # =========================================================================
    
    # Keywords Python
    keywords_python: Set[str] = field(default_factory=lambda: {
        'def', 'class', 'return', 'yield', 'async', 'await',
        'import', 'from', 'as', 'with', 'lambda', 'global', 'nonlocal',
        'True', 'False', 'None', 'pass', 'break', 'continue',
        'raise', 'assert', 'del', 'in', 'is', 'not', 'and', 'or',
    })
    
    # Keywords JavaScript/TypeScript
    keywords_js: Set[str] = field(default_factory=lambda: {
        'function', 'const', 'let', 'var', 'return', 'yield',
        'async', 'await', 'import', 'export', 'from', 'default',
        'class', 'extends', 'super', 'this', 'new', 'delete', 'typeof', 'instanceof',
        'true', 'false', 'null', 'undefined', 'void',
        'throw', 'try', 'catch', 'finally',
    })
    
    # Keywords Rust
    keywords_rust: Set[str] = field(default_factory=lambda: {
        'fn', 'let', 'mut', 'const', 'static', 'return',
        'struct', 'enum', 'impl', 'trait', 'type', 'where',
        'pub', 'crate', 'mod', 'use', 'as', 'self', 'super',
        'match', 'if', 'else', 'loop', 'while', 'for', 'in', 'break', 'continue',
        'async', 'await', 'move', 'unsafe', 'dyn', 'ref',
    })
    
    # Operadores comunes (todos los lenguajes)
    operadores: Set[str] = field(default_factory=lambda: {
        '+', '-', '*', '/', '%', '**', '//',           # Aritm√©ticos
        '=', '+=', '-=', '*=', '/=', '%=',             # Asignaci√≥n
        '==', '!=', '<', '>', '<=', '>=',             # Comparaci√≥n
        '&&', '||', '!', '&', '|', '^', '~',          # L√≥gicos/Bitwise
        '<<', '>>', '>>>', '&=', '|=', '^=',          # Bitwise assign
        '<<=' , '>>=', '//=', '**=',                  # Assignment extended
        '->', '=>', '::', '.', '..', '...',           # Especiales
        '?', '??', '?.', '?:',                        # Ternario/nullish
    })
    
    # Delimitadores
    delimitadores: Set[str] = field(default_factory=lambda: {
        '(', ')', '[', ']', '{', '}',
        ',', ';', ':', '@', '#',
        '"', "'", '`', '"""', "'''",
        '//', '/*', '*/',                             # Comentarios
    })
    
    # =========================================================================
    # TERRITORIO LOGICO - Control flow
    # =========================================================================
    
    control_flow: Set[str] = field(default_factory=lambda: {
        # Condicionales (min√∫sculas y variantes)
        'if', 'else', 'elif', 'switch', 'case', 'default', 'match',
        'If', 'Else', 'Switch', 'Case', 'Default', 'Match',
        # Loops
        'for', 'while', 'do', 'loop', 'foreach',
        'For', 'While', 'Do', 'Loop',
        # Excepciones
        'try', 'except', 'catch', 'finally', 'throw', 'raise',
        'Try', 'Catch', 'Finally', 'Throw', 'Raise',
        # Jumps
        'break', 'continue', 'return', 'yield', 'goto',
        'Break', 'Continue', 'Return', 'Yield',
    })
    
    # =========================================================================
    # TERRITORIO ESTRUCTURAL - Patrones y estructura
    # =========================================================================
    
    # Patrones de indentaci√≥n (Python style)
    patrones_indent: List[str] = field(default_factory=lambda: [
        r'^    ',      # 4 espacios
        r'^\t',        # Tab
        r'^        ',  # 8 espacios
    ])
    
    # Patrones de bloques
    patrones_bloque: List[str] = field(default_factory=lambda: [
        r':\s*$',           # Python: fin de l√≠nea con :
        r'\{\s*$',          # C-style: abrir bloque
        r'^\s*\}',          # C-style: cerrar bloque
        r'^(def|class|fn)\s+\w+',  # Definici√≥n funci√≥n/clase
    ])
    
    # =========================================================================
    # TERRITORIO SEMANTICA - Contexto y significado
    # =========================================================================
    
    # Patrones sem√°nticos
    patron_string: str = r'["\'].*?["\']|""".*?"""|\'\'\'.*?\'\'\''
    patron_comentario: str = r'#.*$|//.*$|/\*.*?\*/|""".*?"""|\'\'\'.*?\'\'\''
    patron_numero: str = r'\b\d+\.?\d*\b'
    patron_nombre: str = r'\b[a-zA-Z_][a-zA-Z0-9_]*\b'
    
    # Tipos built-in (sem√°ntica fuerte)
    tipos_builtin: Set[str] = field(default_factory=lambda: {
        # Python
        'int', 'float', 'str', 'bool', 'list', 'dict', 'set', 'tuple',
        'bytes', 'None', 'type', 'object',
        # TypeScript/JS
        'number', 'string', 'boolean', 'object', 'array', 'any', 'void',
        'null', 'undefined', 'never', 'unknown',
        # Rust
        'i8', 'i16', 'i32', 'i64', 'i128', 'isize',
        'u8', 'u16', 'u32', 'u64', 'u128', 'usize',
        'f32', 'f64', 'bool', 'char', 'str', 'String',
        'Vec', 'Option', 'Result', 'Box', 'Rc', 'Arc',
    })

    def activar_territorios(self, token: str) -> Dict[TipoTerritorioCoder, float]:
        """
        Determina qu√© territorios activa un token y con qu√© peso.
        
        Returns:
            Dict con territorio -> peso de activaci√≥n [0, 1]
        """
        activaciones = {
            TipoTerritorioCoder.SINTAXIS: 0.0,
            TipoTerritorioCoder.SEMANTICA: 0.0,
            TipoTerritorioCoder.LOGICO: 0.0,
            TipoTerritorioCoder.ESTRUCTURAL: 0.0,
        }
        
        # =====================================================================
        # NORMALIZACI√ìN CR√çTICA: Quitar prefijos de SentencePiece/BPE
        # Sin esto '‚ñÅdef' != 'def' y todo va al catch-all SEM√ÅNTICA
        # =====================================================================
        token_original = token
        token = normalizar_token(token)
        
        # Si el token queda vac√≠o despu√©s de normalizar, usar original
        if not token:
            token = token_original
        
        token_lower = token.lower() if token else ""
        
        # =====================================================================
        # SINTAXIS: Keywords y operadores
        # =====================================================================
        if token in self.keywords_python or token in self.keywords_js or token in self.keywords_rust:
            activaciones[TipoTerritorioCoder.SINTAXIS] = 1.0
            
            # Keywords de control flow tambi√©n activan LOGICO
            if token_lower in self.control_flow:
                activaciones[TipoTerritorioCoder.LOGICO] = 0.8
        
        if token in self.operadores:
            activaciones[TipoTerritorioCoder.SINTAXIS] = 0.9
            # Operadores l√≥gicos activan LOGICO
            if token in {'&&', '||', '!', 'and', 'or', 'not'}:
                activaciones[TipoTerritorioCoder.LOGICO] = 0.7
        
        if token in self.delimitadores:
            activaciones[TipoTerritorioCoder.SINTAXIS] = 0.7
            # Brackets activan ESTRUCTURAL fuertemente
            if token in {'{', '}'}:
                activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 1.0  # M√°ximo para bloques
            elif token in {'(', ')', '[', ']'}:
                activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.6
            elif token == ':':
                activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.8  # Python blocks
        
        # =====================================================================
        # LOGICO: Control flow espec√≠fico
        # Verificamos tanto min√∫scula como el token original (case-insensitive)
        # =====================================================================
        if token_lower in self.control_flow or token in self.control_flow:
            activaciones[TipoTerritorioCoder.LOGICO] = 1.0
        
        # =====================================================================
        # ESTRUCTURAL: Indentaci√≥n y patrones
        # =====================================================================
        for patron in self.patrones_indent:
            if re.match(patron, token):
                activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.9
                break
        
        for patron in self.patrones_bloque:
            if re.search(patron, token):
                activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.8
                break
        
        # =====================================================================
        # SEMANTICA: Nombres, tipos, literales
        # =====================================================================
        if token in self.tipos_builtin:
            activaciones[TipoTerritorioCoder.SEMANTICA] = 1.0
        
        # Nombres de variables/funciones (solo si parece identificador)
        if token and re.match(self.patron_nombre, token):
            # Verificar que no sea keyword de ning√∫n lenguaje
            all_keywords = self.keywords_python | self.keywords_js | self.keywords_rust
            if token not in all_keywords and token_lower not in self.control_flow:
                if activaciones[TipoTerritorioCoder.SEMANTICA] == 0.0:
                    activaciones[TipoTerritorioCoder.SEMANTICA] = 0.6
        
        # N√∫meros
        if token and re.match(self.patron_numero, token):
            activaciones[TipoTerritorioCoder.SEMANTICA] = 0.5
            # N√∫meros tambi√©n activan ESTRUCTURAL (patrones num√©ricos)
            activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.3
        
        # =====================================================================
        # CATCH-ALL: Solo si REALMENTE no matche√≥ nada
        # Peso bajo para no dominar el routing
        # =====================================================================
        if sum(activaciones.values()) == 0:
            # Distribuir uniformemente con peso bajo
            activaciones[TipoTerritorioCoder.SEMANTICA] = 0.25
            activaciones[TipoTerritorioCoder.SINTAXIS] = 0.1
            activaciones[TipoTerritorioCoder.ESTRUCTURAL] = 0.1
        
        return activaciones
    
    def clasificar_token(self, token: str) -> Tuple[TipoTerritorioCoder, float]:
        """
        Retorna el territorio principal y su peso.
        """
        activaciones = self.activar_territorios(token)
        territorio_principal = max(activaciones, key=activaciones.get)
        return territorio_principal, activaciones[territorio_principal]


@dataclass
class LlavesCodigoRegistry:
    """
    Registry para mapear tokens de tokenizer a activaciones de territorios.
    
    Se inicializa una vez con el tokenizer y pre-computa las activaciones
    para todos los tokens del vocabulario.
    """
    
    llaves: LlavesCodigo = field(default_factory=LlavesCodigo)
    _cache: Dict[int, Dict[TipoTerritorioCoder, float]] = field(default_factory=dict)
    _tokens: Dict[int, str] = field(default_factory=dict)
    
    def registrar_tokenizer(self, tokenizer) -> None:
        """
        Pre-computa activaciones para todos los tokens del vocabulario.
        """
        print("[LLAVES] Registrando LLAVES para codigo...")
        
        vocab_size = tokenizer.vocab_size() if hasattr(tokenizer, 'vocab_size') else len(tokenizer)
        
        for token_id in range(vocab_size):
            try:
                token_str = tokenizer.id_to_piece(token_id) if hasattr(tokenizer, 'id_to_piece') else tokenizer.decode([token_id])
                self._tokens[token_id] = token_str
                self._cache[token_id] = self.llaves.activar_territorios(token_str)
            except:
                # Token especial o no decodificable
                self._tokens[token_id] = "<unk>"
                self._cache[token_id] = {t: 0.25 for t in TipoTerritorioCoder}
        
        print(f"[OK] {len(self._cache)} tokens registrados")
        self._print_stats()
    
    def _print_stats(self) -> None:
        """Muestra estad√≠sticas de distribuci√≥n."""
        counts = {t: 0 for t in TipoTerritorioCoder}
        
        for activaciones in self._cache.values():
            principal = max(activaciones, key=activaciones.get)
            counts[principal] += 1
        
        total = len(self._cache)
        print("\n[STATS] Distribucion de territorios:")
        for territorio, count in counts.items():
            pct = count / total * 100
            bar = "#" * int(pct / 5)
            print(f"   {territorio.name:12} {bar:20} {pct:.1f}%")
    
    def get_activaciones(self, token_id: int) -> Dict[TipoTerritorioCoder, float]:
        """Obtiene activaciones pre-computadas para un token."""
        return self._cache.get(token_id, {t: 0.25 for t in TipoTerritorioCoder})
    
    def get_activaciones_batch(self, token_ids: List[int]) -> List[Dict[TipoTerritorioCoder, float]]:
        """Obtiene activaciones para un batch de tokens."""
        return [self.get_activaciones(tid) for tid in token_ids]


# =============================================================================
# Demo
# =============================================================================

def demo_llaves():
    """Demo del sistema de LLAVES."""
    llaves = LlavesCodigo()
    
    test_tokens = [
        'def', 'function', 'fn',           # Keywords
        'if', 'while', 'for', 'match',     # Control flow
        '+', '==', '->', '=>',             # Operadores
        '(', '{', '[', ':',                # Delimitadores
        'int', 'str', 'Vec', 'Option',     # Tipos
        'myVariable', 'calculate_sum',      # Nombres
        '42', '3.14',                        # N√∫meros
    ]
    
    print("\n" + "=" * 70)
    print("üîë PAMPAr-Coder LLAVES Demo")
    print("=" * 70)
    
    for token in test_tokens:
        activaciones = llaves.activar_territorios(token)
        principal, peso = llaves.clasificar_token(token)
        
        # Formatear activaciones
        acts_str = " | ".join(
            f"{t.name[:4]}:{v:.1f}" 
            for t, v in activaciones.items() if v > 0
        )
        
        print(f"'{token:15}' ‚Üí {principal.name:12} ({peso:.1f})  [{acts_str}]")


if __name__ == "__main__":
    demo_llaves()
