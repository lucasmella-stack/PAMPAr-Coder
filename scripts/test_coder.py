# SPDX-License-Identifier: AGPL-3.0-or-later
# Copyright (c) 2024-2026 Lucas Ricardo Mella Chillemi
"""
Test de PAMPAr-Coder.

Verifica que todos los componentes funcionan correctamente:
- Config y presets
- LLAVES para c√≥digo
- Territorios
- Modelo completo
- Generaci√≥n
"""

import sys
import time
sys.path.insert(0, '.')

import torch


def test_config():
    """Test de configuraciones."""
    print("\n" + "=" * 70)
    print("üîß Test: Configuraciones")
    print("=" * 70)
    
    from pampar.coder import ConfigPampaRCoder, CODER_4GB, CODER_8GB, CODER_24GB
    
    configs = [
        ("CODER_4GB", CODER_4GB),
        ("CODER_8GB", CODER_8GB),
        ("CODER_24GB", CODER_24GB),
    ]
    
    for name, cfg in configs:
        params = cfg.estimate_params()
        vram = cfg.estimate_vram_gb(training=False)
        print(f"  ‚úì {name}: {params['total']/1e6:.1f}M params, ~{vram:.2f}GB VRAM")
    
    print("  ‚úÖ Configuraciones OK")


def test_llaves():
    """Test del sistema LLAVES."""
    print("\n" + "=" * 70)
    print("üîë Test: Sistema LLAVES")
    print("=" * 70)
    
    from pampar.coder import LlavesCodigo, TipoTerritorioCoder
    
    llaves = LlavesCodigo()
    
    # Test tokens espec√≠ficos
    test_cases = [
        ("def", TipoTerritorioCoder.SINTAXIS),
        ("if", TipoTerritorioCoder.LOGICO),
        ("int", TipoTerritorioCoder.SEMANTICA),
        ("{", TipoTerritorioCoder.SINTAXIS),
    ]
    
    for token, expected_territorio in test_cases:
        territorio, peso = llaves.clasificar_token(token)
        status = "‚úì" if territorio == expected_territorio else "‚úó"
        print(f"  {status} '{token}' ‚Üí {territorio.name} (peso={peso:.1f})")
    
    print("  ‚úÖ LLAVES OK")


def test_territorios():
    """Test de territorios."""
    print("\n" + "=" * 70)
    print("üèõÔ∏è Test: Territorios")
    print("=" * 70)
    
    from pampar.coder import GestorTerritoriosCoder, TipoTerritorioCoder
    
    gestor = GestorTerritoriosCoder(dim=192, n_heads=6, max_len=512)
    
    # Contar par√°metros
    params = sum(p.numel() for p in gestor.parameters())
    print(f"  ‚úì GestorTerritorios: {params:,} par√°metros")
    
    # Test forward
    x = torch.randn(2, 32, 192)
    activaciones = {t: torch.rand(2, 32) for t in TipoTerritorioCoder}
    
    with torch.no_grad():
        out, conf, should_exit = gestor(x, activaciones)
    
    assert out.shape == x.shape, f"Shape mismatch: {out.shape} vs {x.shape}"
    print(f"  ‚úì Forward pass: {x.shape} ‚Üí {out.shape}")
    print(f"  ‚úì Confianza: {conf.mean().item():.3f}")
    
    print("  ‚úÖ Territorios OK")


def test_modelo():
    """Test del modelo completo."""
    print("\n" + "=" * 70)
    print("üöÄ Test: Modelo PampaRCoder")
    print("=" * 70)
    
    from pampar.coder import PampaRCoder, CODER_4GB, crear_modelo
    
    # Crear modelo
    model = crear_modelo("4GB")
    
    # Estad√≠sticas
    params = model.count_parameters()
    print(f"  ‚úì Total par√°metros: {params['total']:,}")
    
    # Test forward
    x = torch.randint(0, CODER_4GB.vocab_size, (2, 64))
    targets = torch.randint(0, CODER_4GB.vocab_size, (2, 64))
    
    logits, loss = model(x, targets)
    
    assert logits.shape == (2, 64, CODER_4GB.vocab_size)
    print(f"  ‚úì Forward: {x.shape} ‚Üí {logits.shape}")
    print(f"  ‚úì Loss: {loss.item():.4f}")
    
    print("  ‚úÖ Modelo OK")


def test_generation():
    """Test de generaci√≥n."""
    print("\n" + "=" * 70)
    print("üéØ Test: Generaci√≥n")
    print("=" * 70)
    
    from pampar.coder import crear_modelo, CODER_4GB
    
    model = crear_modelo("4GB")
    model.eval()
    
    prompt = torch.randint(0, CODER_4GB.vocab_size, (1, 10))
    
    # Sin early exit
    start = time.time()
    gen1 = model.generate(prompt, max_new_tokens=30, use_early_exit=False)
    t1 = time.time() - start
    
    # Con early exit
    start = time.time()
    gen2 = model.generate(prompt, max_new_tokens=30, use_early_exit=True)
    t2 = time.time() - start
    
    print(f"  ‚úì Sin early exit: {gen1.shape[1]} tokens en {t1:.3f}s ({30/t1:.1f} tok/s)")
    print(f"  ‚úì Con early exit: {gen2.shape[1]} tokens en {t2:.3f}s ({30/t2:.1f} tok/s)")
    
    speedup = t1 / t2 if t2 > 0 else 1.0
    print(f"  ‚úì Speedup early exit: {speedup:.2f}x")
    
    print("  ‚úÖ Generaci√≥n OK")


def test_gpu():
    """Test en GPU si est√° disponible."""
    print("\n" + "=" * 70)
    print("üéÆ Test: GPU")
    print("=" * 70)
    
    if not torch.cuda.is_available():
        print("  ‚ö†Ô∏è CUDA no disponible, saltando test GPU")
        return
    
    from pampar.coder import crear_modelo, CODER_4GB
    
    device = torch.device("cuda")
    model = crear_modelo("4GB").to(device)
    
    # Verificar VRAM usada
    torch.cuda.reset_peak_memory_stats()
    
    x = torch.randint(0, CODER_4GB.vocab_size, (4, 128), device=device)
    targets = torch.randint(0, CODER_4GB.vocab_size, (4, 128), device=device)
    
    logits, loss = model(x, targets)
    loss.backward()
    
    vram_used = torch.cuda.max_memory_allocated() / 1024**3
    print(f"  ‚úì GPU: {torch.cuda.get_device_name()}")
    print(f"  ‚úì VRAM usada: {vram_used:.2f} GB")
    print(f"  ‚úì Loss: {loss.item():.4f}")
    
    # Test generaci√≥n en GPU
    model.eval()
    prompt = torch.randint(0, CODER_4GB.vocab_size, (1, 10), device=device)
    
    start = time.time()
    generated = model.generate(prompt, max_new_tokens=50, use_early_exit=True)
    elapsed = time.time() - start
    
    print(f"  ‚úì Generaci√≥n GPU: {50/elapsed:.1f} tokens/sec")
    
    print("  ‚úÖ GPU OK")


def main():
    """Ejecuta todos los tests."""
    print("\n" + "=" * 70)
    print("       PAMPAr-Coder Test Suite")
    print("=" * 70)
    
    try:
        test_config()
        test_llaves()
        test_territorios()
        test_modelo()
        test_generation()
        test_gpu()
        
        print("\n" + "=" * 70)
        print("üéâ TODOS LOS TESTS PASARON")
        print("=" * 70)
        
        # Resumen final
        print("\nüìä Resumen PAMPAr-Coder:")
        from pampar.coder import CODER_4GB, crear_modelo
        
        model = crear_modelo("4GB")
        params = model.count_parameters()
        vram = CODER_4GB.estimate_vram_gb(training=True)
        
        print(f"   Par√°metros:  {params['total']/1e6:.1f}M")
        print(f"   VRAM train:  ~{vram:.2f} GB")
        print(f"   Preset:      CODER_4GB (GTX 1650 compatible)")
        print(f"   Early Exit:  S√≠ (umbral={CODER_4GB.umbral_confianza_exit})")
        print(f"   LLAVES:      {CODER_4GB.peso_llaves*100:.0f}% reglas")
        
        print("\nüöÄ Listo para entrenar!")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
